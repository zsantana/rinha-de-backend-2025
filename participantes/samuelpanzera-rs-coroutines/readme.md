# ğŸ¦€ Rinha de Backend - Samuel Panzera ğŸ¦€

Este projeto Ã© a minha participaÃ§Ã£o na Rinha de Backend! O foco principal foi construir uma API de pagamentos com a **mÃ¡xima performance** possÃ­vel, explorando tecnologias e arquiteturas que otimizam a velocidade e o uso de recursos ao extremo.

## ğŸ¯ O Intuito do Projeto

A meta era clara: criar a API mais rÃ¡pida e eficiente possÃ­vel para o desafio. Para isso, tomei algumas decisÃµes tÃ©cnicas ousadas, mas que se mostraram cruciais para atingir os objetivos de performance no contexto da "rinha".

## ğŸ› ï¸ Stacks e Tecnologias Utilizadas

- **Linguagem:** ğŸ¦€ **Rust** - Escolhido pela sua performance incomparÃ¡vel, seguranÃ§a de memÃ³ria e capacidades de concorrÃªncia de baixo nÃ­vel.
- **Framework Web:** âš™ï¸ **May/May-MiniHttp** - Um framework Rust minimalista que utiliza corrotinas (green threads), permitindo um altÃ­ssimo grau de concorrÃªncia com um custo muito baixo de recursos.
- **Banco de Dados:** Memoria compartilhada para MÃ¡xima perfomance
- **Load Balancer:** **Nginx** - Para distribuir a carga de forma eficiente entre duas instÃ¢ncias da API, garantindo alta disponibilidade e escalabilidade horizontal.
- **ContainerizaÃ§Ã£o:** ğŸ³ **Docker & Docker Compose** - Para facilitar a configuraÃ§Ã£o, o deploy e a execuÃ§Ã£o de todo o ambiente de forma consistente.

## ğŸ—ï¸ DecisÃµes TÃ©cnicas e Arquitetura

```mermaid
flowchart LR
    Client["ğŸ‘¤ Cliente"] --> LB["ğŸ”„ Nginx<br>:9999"]
    LB --> API1["ğŸ¦€ API 1<br>May/MiniHttp"] & API2["ğŸ¦€ API 2<br>May/MiniHttp"]
    API1 --> SM[("ğŸ§  Shared Memory<br>Memory-Mapped File")] & EXT["ğŸŒ Payment Processors<br>"]
    API2 --> SM & EXT
     LB:::balancer
     API1:::api
     API2:::api
     SM:::storage
     EXT:::external
    classDef api fill:#f9a,stroke:#333,stroke-width:2px
    classDef storage fill:#ff9,stroke:#333,stroke-width:3px
    classDef external fill:#99f,stroke:#333,stroke-width:2px
    classDef balancer fill:#9f9,stroke:#333,stroke-width:2px
    style LB fill:#000000
```

### ğŸ—ï¸ Fluxo de Processamento de Pagamentos

1. **ğŸ“¥ RecepÃ§Ã£o:** Cliente envia POST /payments â†’ Nginx distribui para API1 ou API2
2. **âš¡ Queue AssÃ­ncrona:** Payment Handler coloca pagamento na fila assÃ­ncrona (canal mpsc)
3. **ğŸ”„ Worker Background:** Worker processa pagamentos de forma assÃ­ncrona:
   - Tenta 5x no processador padrÃ£o (com delay de 500ms entre tentativas)
   - Se falhar, usa o processador fallback
4. **ğŸ’¾ PersistÃªncia:** Sucesso â†’ salva na memÃ³ria compartilhada (atomic operations)
5. **ğŸ“Š Consulta:** GET /payments-summary lÃª diretamente da memÃ³ria compartilhada

### ğŸ§  Arquitetura de MemÃ³ria Compartilhada

A inovaÃ§Ã£o principal estÃ¡ na **memÃ³ria compartilhada entre as duas instÃ¢ncias da API**:

- **Memory-mapped file** compartilhado via volume Docker
- **OperaÃ§Ãµes atÃ´micas** para thread-safety
- **Zero network overhead** entre instÃ¢ncias para consolidaÃ§Ã£o de dados
- **Cache em memÃ³ria** para mÃ¡xima performance de leitura

A decisÃ£o mais impactante na arquitetura deste projeto foi a escolha de um **banco de dados _embedded_**.

### Por que um Banco de Dados Dentro da API?

- âš¡ **Performance Extrema:** A comunicaÃ§Ã£o com o SQLite Ã© feita atravÃ©s de chamadas de funÃ§Ã£o diretas na memÃ³ria. Isso elimina completamente a latÃªncia de rede (network overhead) que existiria ao se conectar com um serviÃ§o de banco de dados externo (como PostgreSQL ou MySQL). Em um desafio focado em microssegundos, essa diferenÃ§a Ã© brutal.
- ğŸ“‰ **Economia de Recursos:** Manter o banco de dados na mesma instÃ¢ncia da aplicaÃ§Ã£o reduz drasticamente o consumo de memÃ³ria e CPU, jÃ¡ que nÃ£o hÃ¡ um processo separado de banco de dados para gerenciar.

> **âš ï¸âš ï¸âš ï¸ AVISO IMPORTANTEâš ï¸âš ï¸âš ï¸:** Embora essa abordagem seja perfeita para o cenÃ¡rio competitivo da Rinha de Backend, **JAMAIS deve ser feito para projetos em produÃ§Ã£o!** Em um ambiente real, um banco de dados separado (como PostgreSQL) oferece vantagens crÃ­ticas de escalabilidade, seguranÃ§a, manutenibilidade e resiliÃªncia que sÃ£o, na maioria das vezes, mais importantes do que a performance bruta obtida com um banco _embedded_.

## âœ… Checklist de Funcionalidades

### Prontas para a Batalha!

- [x] ğŸš€ API para processamento de pagamentos (`POST /payments`)
- [x] ğŸ“Š API para resumo de pagamentos (`GET /payments-summary`)
- [x] ğŸ—„ï¸ Estrutura e otimizaÃ§Ãµes de uma simulaÃ§Ã£o de banco de dados
- [x] âš–ï¸ ConfiguraÃ§Ã£o do Load Balancer com Nginx para duas instÃ¢ncias
- [x] ğŸ³ ContainerizaÃ§Ã£o completa com Docker e Docker Compose
- [x] ğŸ“… Implementar filtros de data (`from` e `to`) no endpoint de resumo
- [x] ğŸ”„ Implementar a comunicaÃ§Ã£o entre as instÃ¢ncias para consolidar o resumo de pagamentos
- [ ] ğŸ§  Desenvolver a lÃ³gica de seleÃ§Ã£o do processador de pagamento (verificaÃ§Ã£o de `service-health`)
- [x] ğŸ“¤ Implementar a comunicaÃ§Ã£o real com os processadores de pagamento externos

## ğŸš€ Como Executar o Projeto

Para botar a rinha pra rodar, vocÃª sÃ³ precisa do Docker e do Docker Compose instalados.

1.  Clone este repositÃ³rio.
2.  Abra o terminal na pasta raiz do projeto.
3.  Execute o comando mÃ¡gico:

    Bash

    ```
    docker-compose up

    ```

Isso irÃ¡ subir todo o ambiente: as duas instÃ¢ncias da API e o Nginx atuando como load balancer.
